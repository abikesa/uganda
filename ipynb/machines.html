

<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Machines &#8212; The Gambler</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.5ea377869091fd0449014c60fc090103.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-dropdown.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-bootstrap.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/book-stylesheet.css" />
    <link rel="stylesheet" type="text/css" href="../_static/custom.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/sphinx_highlight.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'ipynb/machines';</script>
    <script src="../_static/script.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
        
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="https://facts.net/wp-content/uploads/2023/07/16-facts-about-roulette-1690805803.jpg" class="logo__image only-light" alt="The Gambler - Home"/>
    <script>document.write(`<img src="https://facts.net/wp-content/uploads/2023/07/16-facts-about-roulette-1690805803.jpg" class="logo__image only-dark" alt="The Gambler - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../act1/part1.html">Aim 1</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../act1/chapter1.html">Mortality</a></li>
<li class="toctree-l2"><a class="reference internal" href="../act1/chapter2.html">ESRD</a></li>
<li class="toctree-l2"><a class="reference internal" href="../act1/chapter3.html">Frailty</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../act2/part2.html">Aim 2</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../act2/chapter1.html">Hospitalization</a></li>

<li class="toctree-l2"><a class="reference internal" href="../act2/chapter2.html">Length of Stay</a></li>
<li class="toctree-l2"><a class="reference internal" href="../act2/chapter3.html">Outcomes</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../act3/part3.html">Aim 3</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../act3/act1.html">WebApp</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../act3/part1/part1_1.html">Browser</a></li>
<li class="toctree-l3"><a class="reference internal" href="../act3/part1/part1_2.html">User</a></li>
<li class="toctree-l3"><a class="reference internal" href="../act3/part1/part1_3.html">Annotation</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../act3/act2.html">Deployment</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../act3/part2/part2_1.html">GitHub</a></li>
<li class="toctree-l3"><a class="reference internal" href="../act3/part2/part2_2.html">Tradition</a></li>


<li class="toctree-l3"><a class="reference internal" href="../act3/part2/part2_3.html">Nietzsche</a></li>

</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../act3/act3.html">Iteration</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../act3/part3/part3_1.html">Latest Research</a></li>
<li class="toctree-l3"><a class="reference internal" href="../act3/part3/part3_2.html">Bayesian Updates</a></li>
<li class="toctree-l3"><a class="reference internal" href="../act3/part3/part3_3.html">Missingness and A Priori</a></li>
</ul>
</details></li>
</ul>
</details></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://mybinder.org/v2/gh/abikesa/template/main?urlpath=tree/book/website/ipynb/machines.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch on Binder"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img alt="Binder logo" src="../_static/images/logo_binder.svg">
  </span>
<span class="btn__text-container">Binder</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/ipynb/machines.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Machines</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#business-feeding-the-machine">Business | Feeding the machine</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-are-the-threats-to-the-1tn-artificial-intelligence-boom">What are the threats to the $1tn artificial-intelligence boom?</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#a-fast-growing-supply-chain-is-at-risk-of-over-extending">A fast-growing supply chain is at risk of over-extending</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#character-arc">Character arc</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ii-departure-from-path-of-forebears-by-the-fledgling">ii. Departure from path of forebears by the <code class="docutils literal notranslate"><span class="pre">fledgling</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#v7-struggles-breed-a-form-of-collective-idealism">V7. Struggles breed a form of collective <code class="docutils literal notranslate"><span class="pre">idealism</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#i-returning-home-to-the-divinity-of-self">I. Returning home to the divinity of <code class="docutils literal notranslate"><span class="pre">self</span></code></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#personalized-service">Personalized service</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#essays">Essays</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mandarine">1 Mandarine</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#language">2 Language</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#autoencoders-and-human-expression">Autoencoders and Human Expression</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#evolution-of-language-and-art">Evolution of Language and Art</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#similarities-with-llm-and-ai">Similarities with LLM and AI</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusion">Conclusion</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers">3 Transformers</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#mean-as-data-tokens">Mean (μ) as Data Tokens</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#context-as-contextual-understanding">Context (σ) as Contextual Understanding</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#pretext-as-predictive-accuracy">Pretext (%) as Predictive Accuracy</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#detailed-breakdown">Detailed Breakdown</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#analogy-to-transformers">Analogy to Transformers</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">Conclusion</a></li>
</ul>
</li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="machines">
<span id="id1"></span><h1>Machines<a class="headerlink" href="#machines" title="Permalink to this heading">#</a></h1>
<section id="business-feeding-the-machine">
<h2><a class="reference external" href="https://www.ft.com/content/b7570359-f809-49ce-8cd5-9166d36a057b">Bus</a><a class="reference external" href="https://www.economist.com/business/2024/07/28/what-are-the-threats-to-the-1trn-artificial-intelligence-boom#">iness</a> | Feeding the machine<a class="headerlink" href="#business-feeding-the-machine" title="Permalink to this heading">#</a></h2>
</section>
<section id="what-are-the-threats-to-the-1tn-artificial-intelligence-boom">
<h2>What are the threats to the $1tn artificial-intelligence boom?<a class="headerlink" href="#what-are-the-threats-to-the-1tn-artificial-intelligence-boom" title="Permalink to this heading">#</a></h2>
<section id="a-fast-growing-supply-chain-is-at-risk-of-over-extending">
<h3>A fast-growing supply chain is at risk of over-extending<a class="headerlink" href="#a-fast-growing-supply-chain-is-at-risk-of-over-extending" title="Permalink to this heading">#</a></h3>
<p><img alt="" src="https://www.economist.com/cdn-cgi/image/width=1424,quality=80,format=auto/content-assets/images/20240803_WBD001.jpg" /></p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>                1. f(t)
                       \
            2. S(t) -&gt; 4. y:h&#39;f(t)=0;t(X&#39;X).X&#39;Y -&gt; 5. b -&gt; 6. SV&#39;
                       /
                       3. h(t)
</pre></div>
</div>
</section>
</section>
<section id="character-arc">
<h2>Character arc<a class="headerlink" href="#character-arc" title="Permalink to this heading">#</a></h2>
<section id="ii-departure-from-path-of-forebears-by-the-fledgling">
<h3>ii. Departure from path of forebears by the <code class="docutils literal notranslate"><span class="pre">fledgling</span></code><a class="headerlink" href="#ii-departure-from-path-of-forebears-by-the-fledgling" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(f(t)\)</span> The harmonic series implied when a single root note is sounded</p></li>
<li><p><span class="math notranslate nohighlight">\(S(t)\)</span> Unifying ii-V7-I arc (variations by mode, qualities, relatives is seperate issue)</p></li>
<li><p><span class="math notranslate nohighlight">\(h(t)\)</span> Landscape of travelled &amp; less travelled paths <span id="id2"><sup><a class="reference internal" href="../act3/part3/part3_3.html#id55" title="Robert Frost. The Road Not Taken. Henry Holt and Company, New York, 1916. Famous quote: &quot;I took the one less traveled by, And that has made all the difference.&quot;.">74</a></sup></span></p></li>
</ul>
</section>
<section id="v7-struggles-breed-a-form-of-collective-idealism">
<h3>V7. Struggles breed a form of collective <code class="docutils literal notranslate"><span class="pre">idealism</span></code><a class="headerlink" href="#v7-struggles-breed-a-form-of-collective-idealism" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\((X'X)^T \cdot X'Y\)</span> Collective Unconscious that allows for for <em>Dhatemwa Kulala, Dhayawukana Emibala</em></p></li>
</ul>
</section>
<section id="i-returning-home-to-the-divinity-of-self">
<h3>I. Returning home to the divinity of <code class="docutils literal notranslate"><span class="pre">self</span></code><a class="headerlink" href="#i-returning-home-to-the-divinity-of-self" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\beta\)</span> Conceptualized as a hierarchy or rank-order of “weights” and “tensions”:</p>
<ul>
<li><p>qualities: melody &lt; dyad &lt; triad</p></li>
<li><p>extensions: &lt; 7th &lt; 9th &lt; 11th &lt; 13th</p></li>
<li><p>alterations: <code class="docutils literal notranslate"><span class="pre">b</span></code>, <code class="docutils literal notranslate"><span class="pre">#</span></code></p></li>
</ul>
</li>
<li><p><span class="math notranslate nohighlight">\(SV'\)</span></p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">individual</span></code>: how many of the “barriers have been encountered and overcome?</p></li>
<li><p>change of mode, quality, relative?</p></li>
<li><p>diatonic: min7b5, dom7(#9, b9, b13), dim, etc</p></li>
</ul>
</li>
</ul>
</section>
</section>
<section id="personalized-service">
<h2>Personalized service<a class="headerlink" href="#personalized-service" title="Permalink to this heading">#</a></h2>
<p>The “quality” of AI is linked to the number of parameters needed to accurately predict the needs of individual users. With 10 billion humans, 10,000 genetic loci, each with 2-100 variants, and with functional interactions amongst them and environement, you can do the math to show that there’s no upper limit to the quality of AI.</p>
<p>What is required for the very best-in-class is a self-updating, self-improving, self-learning system that gets better and better, with better customization for the end-user.</p>
<p>Quick deployment and transportation do not seem to be limiting factors in this landscape of affairs. Its the sheer amount of “compute” and the energy it will demand. We are less inclined to bothere ourselves with the quality of the data on which it is trained, since simulation is a viable alternative, with increased quality of simulations over time</p>
<blockquote>
<div><p><em>This framework captures concepts like average-joe (base-case), national-character (group), stereotype (subgroup), and individualized (accurate). Trumps inaccuracies about Kamala are are failure to see that “accurate representation” is the sum of all subgroups one belongs to. Not surprising from an average Joe</em></p>
</div></blockquote>
<ul class="simple">
<li><p>Base-case</p>
<ul>
<li><p><span class="math notranslate nohighlight">\(f(t)\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(S(t)\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(h(t)\)</span></p></li>
</ul>
</li>
<li><p>Group <span class="math notranslate nohighlight">\((X'X)^T \cdot X'Y\)</span></p></li>
<li><p>Individual</p>
<ul>
<li><p>Subgroup <span class="math notranslate nohighlight">\(\beta\)</span></p></li>
<li><p>Personalized <span class="math notranslate nohighlight">\(SV'\)</span></p></li>
</ul>
</li>
</ul>
</section>
<section id="essays">
<h2>Essays<a class="headerlink" href="#essays" title="Permalink to this heading">#</a></h2>
<section id="mandarine">
<h3>1 Mandarine<a class="headerlink" href="#mandarine" title="Permalink to this heading">#</a></h3>
<p>The notion that Chinese characters, particularly those in Mandarin, were originally representational holds a significant amount of truth. Chinese characters, or 汉字 (hànzì), have evolved over thousands of years. Initially, many of these characters were indeed pictographic, meaning they visually represented the objects or concepts they stood for.</p>
<p>For example, the character for “sun” (日, rì) originally looked more like a circular representation of the sun, and the character for “tree” (木, mù) resembled a tree. These early forms, known as oracle bone script, date back to the Shang Dynasty (circa 1600-1046 BCE). Over time, these pictographic characters evolved into more abstract forms.</p>
<p>As Chinese script developed, it incorporated other principles beyond simple pictography. There are six main types of Chinese characters:</p>
<ol class="arabic simple">
<li><p><strong>Pictographs (象形, xiàngxíng)</strong>: Characters that visually resemble the objects they represent (e.g., 山 for mountain).</p></li>
<li><p><strong>Ideographs (指事, zhǐshì)</strong>: Characters that represent abstract ideas through symbolic representation (e.g., 上 for above).</p></li>
<li><p><strong>Compound ideographs (会意, huìyì)</strong>: Characters that combine two or more elements to suggest a new meaning (e.g., 明 for bright, combining 日 and 月 for sun and moon).</p></li>
<li><p><strong>Phono-semantic compounds (形声, xíngshēng)</strong>: Characters that combine a meaning component (radical) with a phonetic component (e.g., 河 for river, where 氵 indicates water and 可 gives the pronunciation).</p></li>
<li><p><strong>Rebus (假借, jiǎjiè)</strong>: Characters borrowed to represent words with similar pronunciations regardless of original meaning (e.g., 来 originally meant “wheat” but is now used to mean “come”).</p></li>
<li><p><strong>Derivative cognates (转注, zhuǎnzhù)</strong>: Characters that are logically extended from existing ones.</p></li>
</ol>
<p>While modern Chinese characters are not purely pictographic, the historical roots are deeply embedded in their structure. Today’s characters have become more abstract and standardized, functioning more like letters in an alphabet, especially when it comes to their use in modern communication and computing. They are no longer just visual representations of objects but are intricate systems combining meaning and sound.</p>
<p>In essence, while the representational nature of Chinese characters has diminished over time, they still retain elements of their pictographic origins. The transition from representational forms to more abstract, symbolic forms is a fascinating aspect of the evolution of the Chinese writing system.</p>
</section>
<section id="language">
<h3>2 Language<a class="headerlink" href="#language" title="Permalink to this heading">#</a></h3>
<p>You’ve touched on a profound and fascinating analogy. The comparison between autoencoders in machine learning and the evolution of human language and art is indeed striking. Let’s explore this analogy further.</p>
<section id="autoencoders-and-human-expression">
<h4>Autoencoders and Human Expression<a class="headerlink" href="#autoencoders-and-human-expression" title="Permalink to this heading">#</a></h4>
<p><strong>Autoencoders:</strong></p>
<ol class="arabic simple">
<li><p><strong>Encoding:</strong> The input data is compressed into a latent space representation, capturing essential features while discarding noise and redundancy.</p></li>
<li><p><strong>Latent Space:</strong> This reduced representation holds the core information necessary to reconstruct the original input.</p></li>
<li><p><strong>Decoding:</strong> The latent representation is transformed back into a format resembling the original input, highlighting the key features identified during encoding.</p></li>
</ol>
<p><strong>Human Expression:</strong></p>
<ol class="arabic simple">
<li><p><strong>Input (Experience):</strong> Humans encounter and perceive the world through sensory inputs and experiences.</p></li>
<li><p><strong>Encoding (Cognition):</strong> The brain processes and compresses these experiences into abstract concepts, symbols, and language.</p></li>
<li><p><strong>Latent Space (Memory and Thought):</strong> These compressed representations are stored in our memory, where they can be manipulated, combined, and recalled.</p></li>
<li><p><strong>Decoding (Expression):</strong> We express these internal representations through language, art, and other forms of communication, conveying our internal thoughts and experiences to others.</p></li>
</ol>
</section>
<section id="evolution-of-language-and-art">
<h4>Evolution of Language and Art<a class="headerlink" href="#evolution-of-language-and-art" title="Permalink to this heading">#</a></h4>
<p><strong>Ancient Cave Paintings and Hieroglyphics:</strong></p>
<ul class="simple">
<li><p><strong>Encoding Experiences:</strong> Early humans encoded their experiences and understanding of the world through visual symbols, such as cave paintings and hieroglyphics. These symbols were direct representations of their observations, beliefs, and daily life.</p></li>
<li><p><strong>Latent Space:</strong> These symbols acted as the latent space, holding essential information about their culture, environment, and cognitive processes.</p></li>
<li><p><strong>Decoding and Communication:</strong> Future generations decoded these symbols, extracting meaning and understanding from them, much like how we decode written text today.</p></li>
</ul>
<p><strong>Chinese Characters:</strong></p>
<ul class="simple">
<li><p><strong>Pictographs and Ideographs:</strong> Early Chinese characters began as pictographs and ideographs, directly representing objects and ideas.</p></li>
<li><p><strong>Phono-semantic Compounds:</strong> Over time, the system evolved to include phonetic elements, making the language more versatile and abstract.</p></li>
<li><p><strong>Modern Use:</strong> Today, Chinese characters have become a sophisticated system that, while retaining elements of their pictographic origins, functions as a highly abstract and symbolic form of communication.</p></li>
</ul>
</section>
<section id="similarities-with-llm-and-ai">
<h4>Similarities with LLM and AI<a class="headerlink" href="#similarities-with-llm-and-ai" title="Permalink to this heading">#</a></h4>
<p><strong>Latent Space in AI:</strong></p>
<ul class="simple">
<li><p><strong>Training:</strong> Large Language Models (LLMs) like GPT-4 are trained on vast amounts of text data, learning patterns, structures, and meanings.</p></li>
<li><p><strong>Latent Representation:</strong> During this process, they encode linguistic features into a latent space, capturing the essence of language use.</p></li>
<li><p><strong>Generation:</strong> When generating text, these models decode the latent representations to produce coherent and contextually appropriate responses.</p></li>
</ul>
<p><strong>Human Mind and Language:</strong></p>
<ul class="simple">
<li><p><strong>Pattern Recognition:</strong> Both AI models and the human brain excel at recognizing patterns and structures in data.</p></li>
<li><p><strong>Abstraction:</strong> Both can abstract complex ideas into simpler representations (latent space) and then reconstruct or express them in various forms.</p></li>
<li><p><strong>Communication:</strong> Just as AI can generate text based on encoded knowledge, humans use language and art to communicate encoded thoughts and experiences.</p></li>
</ul>
</section>
<section id="conclusion">
<h4>Conclusion<a class="headerlink" href="#conclusion" title="Permalink to this heading">#</a></h4>
<p>The analogy between autoencoders, AI, and human language is a compelling way to understand how we process and communicate information. Both systems involve encoding experiences into a compressed form, storing these representations, and then decoding them for expression and communication. This parallel highlights the deep connections between technology, cognition, and the evolution of human expression.</p>
</section>
</section>
<section id="transformers">
<h3>3 Transformers<a class="headerlink" href="#transformers" title="Permalink to this heading">#</a></h3>
<p>Your framework is a nuanced way to understand the process of how transformers, including large language models like GPT-4, work. Let’s delve deeper into your analogy:</p>
<section id="mean-as-data-tokens">
<h4>Mean (μ) as Data Tokens<a class="headerlink" href="#mean-as-data-tokens" title="Permalink to this heading">#</a></h4>
<p>In your analogy, <strong>text (μ)</strong> represents the mean, or the central tendency of the data on which the model was trained. This includes all the tokens (words, subwords, characters) that the model has learned from during its training phase. These tokens are the raw input data, and the mean represents a kind of average understanding of the language.</p>
</section>
<section id="context-as-contextual-understanding">
<h4>Context (σ) as Contextual Understanding<a class="headerlink" href="#context-as-contextual-understanding" title="Permalink to this heading">#</a></h4>
<p><strong>Context (σ)</strong> represents the standard deviation or the spread of the data around the mean. In the context of transformers, this spread can be thought of as the model’s ability to understand and generate context. The transformer model uses attention mechanisms to weigh the importance of each token relative to others in the sequence, allowing it to look around the mean and grasp the nuances and subtleties of language.</p>
</section>
<section id="pretext-as-predictive-accuracy">
<h4>Pretext (%) as Predictive Accuracy<a class="headerlink" href="#pretext-as-predictive-accuracy" title="Permalink to this heading">#</a></h4>
<p><strong>Pretext (%)</strong> refers to the accuracy or probability of predicting the next token. The transformer introduces some “bias” or “error” by looking at the context around each token. This bias is not a negative error but rather a crucial part of the model’s ability to understand and generate coherent text. By considering the surrounding context, the model improves its predictions, leading to higher accuracy.</p>
</section>
<section id="detailed-breakdown">
<h4>Detailed Breakdown<a class="headerlink" href="#detailed-breakdown" title="Permalink to this heading">#</a></h4>
<ol class="arabic simple">
<li><p><strong>Text (μ):</strong> The mean represents the central value of the tokens, essentially capturing the basic, average representation of the language data the model was trained on. Each token has a vector representation in the model’s embedding space.</p></li>
<li><p><strong>Context (σ):</strong> The transformer architecture uses mechanisms like self-attention to capture context. This involves calculating attention scores that determine the relevance of each token in a sequence to the current token being processed. These scores introduce variability around the mean, helping the model to consider a wide range of possible contexts, much like the spread (σ) in a statistical distribution.</p></li>
<li><p><strong>Pretext (%):</strong> The model uses its understanding of context to predict the next token with a certain probability. This probability can be seen as a measure of accuracy, reflecting how confident the model is in its prediction based on the learned context. The “bias” introduced by the attention mechanism enhances this predictive accuracy, allowing the model to generate more contextually appropriate and coherent text.</p></li>
</ol>
</section>
<section id="analogy-to-transformers">
<h4>Analogy to Transformers<a class="headerlink" href="#analogy-to-transformers" title="Permalink to this heading">#</a></h4>
<ul class="simple">
<li><p><strong>Tokens as Mean (μ):</strong> During training, the model learns the average representation of each token in various contexts, building a robust embedding space.</p></li>
<li><p><strong>Attention Mechanism as Spread (σ):</strong> The attention mechanism enables the model to weigh the importance of each token in a sequence, effectively “looking around the mean” to capture the context. This is akin to considering the spread of data points around the mean.</p></li>
<li><p><strong>Predictive Accuracy as Pretext (%):</strong> The model’s ability to predict the next token is enhanced by its contextual understanding. The attention scores introduce a form of “bias” that improves the model’s accuracy in generating the next token, much like how considering variance can provide a more accurate picture in statistics.</p></li>
</ul>
</section>
<section id="id3">
<h4>Conclusion<a class="headerlink" href="#id3" title="Permalink to this heading">#</a></h4>
<p>Your analogy captures the essence of how transformers function. The mean (μ) represents the core data (tokens), the context (σ) reflects the model’s ability to understand the relationships between these tokens, and the pretext (%) signifies the model’s predictive accuracy. By introducing context-aware “bias” through mechanisms like self-attention, the transformer improves its ability to generate accurate and coherent text. This analogy helps demystify the complex inner workings of language models and highlights the sophisticated interplay between data, context, and prediction in these advanced AI systems.</p>
</section>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./ipynb"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#business-feeding-the-machine">Business | Feeding the machine</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-are-the-threats-to-the-1tn-artificial-intelligence-boom">What are the threats to the $1tn artificial-intelligence boom?</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#a-fast-growing-supply-chain-is-at-risk-of-over-extending">A fast-growing supply chain is at risk of over-extending</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#character-arc">Character arc</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ii-departure-from-path-of-forebears-by-the-fledgling">ii. Departure from path of forebears by the <code class="docutils literal notranslate"><span class="pre">fledgling</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#v7-struggles-breed-a-form-of-collective-idealism">V7. Struggles breed a form of collective <code class="docutils literal notranslate"><span class="pre">idealism</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#i-returning-home-to-the-divinity-of-self">I. Returning home to the divinity of <code class="docutils literal notranslate"><span class="pre">self</span></code></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#personalized-service">Personalized service</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#essays">Essays</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mandarine">1 Mandarine</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#language">2 Language</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#autoencoders-and-human-expression">Autoencoders and Human Expression</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#evolution-of-language-and-art">Evolution of Language and Art</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#similarities-with-llm-and-ai">Similarities with LLM and AI</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusion">Conclusion</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformers">3 Transformers</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#mean-as-data-tokens">Mean (μ) as Data Tokens</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#context-as-contextual-understanding">Context (σ) as Contextual Understanding</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#pretext-as-predictive-accuracy">Pretext (%) as Predictive Accuracy</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#detailed-breakdown">Detailed Breakdown</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#analogy-to-transformers">Analogy to Transformers</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">Conclusion</a></li>
</ul>
</li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
<div class="extra_footer">
  Copyright © 2025 ADM

</div>
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>